{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd5e0a17-89cf-4c83-9edc-f930b31599af",
   "metadata": {},
   "source": [
    "# Activity 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f706e32-0ac7-4485-a7b9-78f151aed8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance Summary:\n",
      "--------------------------------------------------\n",
      "Polynomial Model:\n",
      "Training MSE: 0.0096\n",
      "Test MSE: 0.0103\n",
      "\n",
      "Gaussian Model:\n",
      "Training MSE: 0.0096\n",
      "Test MSE: 0.0103\n",
      "\n",
      "Sigmoid Model:\n",
      "Training MSE: 0.0096\n",
      "Test MSE: 0.0103\n",
      "\n",
      "\n",
      "Bayesian Linear Regression Results:\n",
      "--------------------------------------------------\n",
      "polynomial_basis:\n",
      "Test MSE: 0.0103\n",
      "\n",
      "gaussian_basis:\n",
      "Test MSE: 0.0103\n",
      "\n",
      "sigmoid_basis:\n",
      "Test MSE: 0.0104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import least_squares\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data generation function\n",
    "def generate_data(samples=1000, p=0.5, noise_std=0.1):\n",
    "    X = np.random.binomial(1, p, samples)\n",
    "    # Add some noise and non-linearity to make the problem more interesting\n",
    "    y = X + np.sin(X * 2) + np.random.normal(0, noise_std, samples)\n",
    "    return X.reshape(-1, 1), y\n",
    "\n",
    "# Polynomial basis functions\n",
    "def polynomial_basis(X, degree=11):\n",
    "    X = X.flatten()\n",
    "    return np.vstack([X**i for i in range(degree+1)]).T\n",
    "\n",
    "# Gaussian basis functions\n",
    "def gaussian_basis(X, num_centers=11):\n",
    "    X = X.flatten()\n",
    "    centers = np.linspace(np.min(X), np.max(X), num_centers)\n",
    "    width = (centers[1] - centers[0]) if len(centers) > 1 else 1.0\n",
    "    return np.vstack([norm.pdf(X, loc=center, scale=width) for center in centers]).T\n",
    "\n",
    "# Sigmoidal basis functions\n",
    "def sigmoid_basis(X, num_centers=11):\n",
    "    X = X.flatten()\n",
    "    centers = np.linspace(np.min(X), np.max(X), num_centers)\n",
    "    width = (centers[1] - centers[0]) if len(centers) > 1 else 1.0\n",
    "    return np.vstack([1 / (1 + np.exp(-(X - center) / width)) for center in centers]).T\n",
    "\n",
    "# Least squares fitting function\n",
    "def fit_model(X, y, basis_func, **basis_params):\n",
    "    phi = basis_func(X, **basis_params)\n",
    "    # Use np.linalg.lstsq for direct solution of least squares\n",
    "    weights, residuals, rank, s = np.linalg.lstsq(phi, y, rcond=None)\n",
    "    return weights\n",
    "\n",
    "# Prediction function\n",
    "def predict(X, weights, basis_func, **basis_params):\n",
    "    phi = basis_func(X, **basis_params)\n",
    "    return phi @ weights\n",
    "\n",
    "# Bayesian Linear Regression\n",
    "def bayesian_linear_regression(X, y, basis_func, alpha=1.0, beta=1.0, **basis_params):\n",
    "    phi = basis_func(X, **basis_params)\n",
    "    S_N_inv = alpha * np.eye(phi.shape[1]) + beta * phi.T @ phi\n",
    "    S_N = np.linalg.inv(S_N_inv)\n",
    "    m_N = beta * S_N @ phi.T @ y\n",
    "    return m_N, S_N\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def evaluate_model(X_train, y_train, X_test, y_test, weights, basis_func, **basis_params):\n",
    "    y_pred_train = predict(X_train, weights, basis_func, **basis_params)\n",
    "    y_pred_test = predict(X_test, weights, basis_func, **basis_params)\n",
    "    \n",
    "    train_mse = np.mean((y_train - y_pred_train) ** 2)\n",
    "    test_mse = np.mean((y_test - y_pred_test) ** 2)\n",
    "    \n",
    "    return train_mse, test_mse\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate data\n",
    "    np.random.seed(42)\n",
    "    X, y = generate_data(samples=1000)\n",
    "    \n",
    "    # Split into train and test sets\n",
    "    train_idx = np.random.choice(len(X), int(0.8*len(X)), replace=False)\n",
    "    test_idx = np.array(list(set(range(len(X))) - set(train_idx)))\n",
    "    \n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "    \n",
    "    # Dictionary to store results\n",
    "    results = {}\n",
    "    \n",
    "    # 1. Polynomial Model\n",
    "    poly_weights = fit_model(X_train, y_train, polynomial_basis)\n",
    "    poly_train_mse, poly_test_mse = evaluate_model(\n",
    "        X_train, y_train, X_test, y_test, \n",
    "        poly_weights, polynomial_basis\n",
    "    )\n",
    "    results['polynomial'] = (poly_train_mse, poly_test_mse)\n",
    "    \n",
    "    # 2. Gaussian Model\n",
    "    gauss_weights = fit_model(X_train, y_train, gaussian_basis)\n",
    "    gauss_train_mse, gauss_test_mse = evaluate_model(\n",
    "        X_train, y_train, X_test, y_test, \n",
    "        gauss_weights, gaussian_basis\n",
    "    )\n",
    "    results['gaussian'] = (gauss_train_mse, gauss_test_mse)\n",
    "    \n",
    "    # 3. Sigmoidal Model\n",
    "    sigmoid_weights = fit_model(X_train, y_train, sigmoid_basis)\n",
    "    sigmoid_train_mse, sigmoid_test_mse = evaluate_model(\n",
    "        X_train, y_train, X_test, y_test, \n",
    "        sigmoid_weights, sigmoid_basis\n",
    "    )\n",
    "    results['sigmoid'] = (sigmoid_train_mse, sigmoid_test_mse)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nModel Performance Summary:\")\n",
    "    print(\"-\" * 50)\n",
    "    for model_name, (train_mse, test_mse) in results.items():\n",
    "        print(f\"{model_name.capitalize()} Model:\")\n",
    "        print(f\"Training MSE: {train_mse:.4f}\")\n",
    "        print(f\"Test MSE: {test_mse:.4f}\\n\")\n",
    "        \n",
    "    # Bayesian Linear Regression for all three models\n",
    "    print(\"\\nBayesian Linear Regression Results:\")\n",
    "    print(\"-\" * 50)\n",
    "    for basis_func in [polynomial_basis, gaussian_basis, sigmoid_basis]:\n",
    "        m_N, S_N = bayesian_linear_regression(X_train, y_train, basis_func)\n",
    "        y_pred = predict(X_test, m_N, basis_func)\n",
    "        mse = np.mean((y_test - y_pred) ** 2)\n",
    "        print(f\"{basis_func.__name__}:\")\n",
    "        print(f\"Test MSE: {mse:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc120052-78fc-40a0-bc52-09afef9ecb11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
